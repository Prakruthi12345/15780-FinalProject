{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pil1pg-RislM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "!pip install supervision\n",
        "import supervision as sv\n",
        "import os\n",
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7M_W9Choi9Xp",
        "outputId": "eeec2ebf-dcb6-41d8-f977-2c36589749e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "MU2deJidislO"
      },
      "outputs": [],
      "source": [
        "#cap=cv2.VideoCapture(\"sb-camera1-0805am-0820am.avi\")\n",
        "#SOURCE_VIDEO_PATH=\"/content/drive/MyDrive/peachtree-camera1-1245pm-0100pm.avi\"\n",
        "#SOURCE_VIDEO_PATH=\"/content/drive/MyDrive/nb-camera1-0400pm-0415pm.avi\"\n",
        "SOURCE_VIDEO_PATH=\"/content/drive/MyDrive/lankershim-camera1-0830am-0845am.avi\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-5w8_qVJislO",
        "outputId": "8b094a01-2e77-45e8-8af4-f29268f7e840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "MODEL = \"yolov8x.pt\"\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_info = sv.VideoInfo.from_video_path(video_path=SOURCE_VIDEO_PATH)\n",
        "\n",
        "video_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wQTAsPIyDy3b",
        "outputId": "c07d1392-7dfd-4b2d-a61c-c41425547a15"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VideoInfo(width=640, height=480, fps=10, total_frames=11220)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "exokDQ2pislP"
      },
      "outputs": [],
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "selected_classes = [2, 3, 5, 7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CNlxA3xislP"
      },
      "outputs": [],
      "source": [
        "# create frame generator\n",
        "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "byte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=10)\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model.track(frame, tracker=\"botsort.yaml\", verbose=False)[0]\n",
        "\n",
        "# convert to Detections\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "# only consider class id from selected_classes define above\n",
        "detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "detections = byte_tracker.update_with_detections(detections)\n",
        "print(detections)\n",
        "print(list(detections.tracker_id))\n",
        "\n",
        "\n",
        "# annotate and display frame\n",
        "anotated_frame=box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(anotated_frame, (16,16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWkZ9cf6islP"
      },
      "outputs": [],
      "source": [
        "detections.xyxy[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjpHlqw1islQ"
      },
      "outputs": [],
      "source": [
        "# create frame generator\n",
        "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "byte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=10)\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "# acquire first video frame\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "i=0\n",
        "x=[]\n",
        "y=[]\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "j = 0\n",
        "my_coords = {}\n",
        "\n",
        "\n",
        "for frame in generator:\n",
        "    print(j)\n",
        "    if j < 5:\n",
        "      print(my_coords)\n",
        "    if j > 5000:\n",
        "      break\n",
        "    if True:\n",
        "      results = model.track(frame, tracker=\"botsort.yaml\", verbose=False)[0]\n",
        "\n",
        "      # convert to Detections\n",
        "      detections = sv.Detections.from_ultralytics(results)\n",
        "      # only consider class id from selected_classes define above\n",
        "\n",
        "      detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "\n",
        "      detections = byte_tracker.update_with_detections(detections)\n",
        "\n",
        "      '''anotated_frame=box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "      %matplotlib inline\n",
        "      sv.plot_image(anotated_frame, (16,16))'''\n",
        "\n",
        "\n",
        "      ids = (list(detections.tracker_id))\n",
        "      for i in range(len(ids)):\n",
        "        #each object get mid coordinates\n",
        "        id = ids[i]\n",
        "        det=detections.xyxy[i]\n",
        "        x=((det[0]+det[2])/2)\n",
        "        y=((det[1]+det[3])/2)\n",
        "\n",
        "        if id not in my_coords:\n",
        "          my_coords[id] = [(x,y,j)]\n",
        "        else:\n",
        "          my_coords[id].append((x,y,j))\n",
        "    j+=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_coords = my_coords.copy()\n",
        "for key in my_coords.keys():\n",
        "  final_coords[key] = my_coords[key].copy()"
      ],
      "metadata": {
        "id": "k9RUPt2AgxKP"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in final_coords.keys():\n",
        "  for i in range(len(final_coords[key])):\n",
        "    final_coords[key][i] = (key,)+final_coords[key][i]"
      ],
      "metadata": {
        "id": "fP7IqGrnW0TH"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_coords = {}\n",
        "for key in final_coords.keys():\n",
        "  count = 0\n",
        "  final = []\n",
        "  break_or_not = False\n",
        "  for i in range(len(final_coords[key])):\n",
        "    prev_count = final_coords[key][i-1][3]\n",
        "    curr_val = final_coords[key][i][3]\n",
        "    temp = []\n",
        "    if curr_val != count:\n",
        "      prev_x = final_coords[key][i-1][1]\n",
        "      prev_y = final_coords[key][i-1][2]\n",
        "      curr_x = final_coords[key][i][1]\n",
        "      curr_y = final_coords[key][i][2]\n",
        "      track = 1\n",
        "      print((i,curr_val,count))\n",
        "      for j in range(count,curr_val):\n",
        "        if prev_x > curr_x:\n",
        "          x = prev_x - ((abs(curr_x-prev_x)/(curr_val-prev_count))*track)\n",
        "        else:\n",
        "          x = prev_x + ((abs(curr_x-prev_x)/(curr_val-prev_count))*track)\n",
        "        if prev_y > curr_y:\n",
        "          y = prev_y - ((abs(curr_y-prev_y)/(curr_val-prev_count))*track)\n",
        "        else:\n",
        "          y = prev_y+ ((abs(curr_y-prev_y)/(curr_val-prev_count))*track)\n",
        "        track+=1\n",
        "        temp.append((key,x,y,j))\n",
        "      print(temp)\n",
        "      temp.append((key,final_coords[key][i][1],final_coords[key][i][2],final_coords[key][i][3]))\n",
        "      count = curr_val+1\n",
        "      final+=temp\n",
        "    else:\n",
        "      count+=1\n",
        "      final.append((key,final_coords[key][i][1],final_coords[key][i][2],final_coords[key][i][3]))\n",
        "  if not break_or_not:\n",
        "    new_coords[key] = final\n",
        ""
      ],
      "metadata": {
        "id": "5gTTuxJ_Y_78"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance"
      ],
      "metadata": {
        "id": "p0hrZg9x2LxP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_coords"
      ],
      "metadata": {
        "id": "pgtOljfEueca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "for key in new_coords.keys():\n",
        "  x = new_coords[key]\n",
        "  new_coords[key] = [t for t in x if not any(isinstance(n, float) and math.isnan(n) for n in t)]"
      ],
      "metadata": {
        "id": "VE-BtkD-z5kg"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in new_coords.keys():\n",
        "  for i in range(1,len(new_coords[key])):\n",
        "    (p_x,p_y) = (new_coords[key][i-1][1],new_coords[key][i-1][2])\n",
        "    (x,y) = (new_coords[key][i][1],new_coords[key][i][2])\n",
        "    new_coords[key][i] = new_coords[key][i]+(distance.euclidean((p_x,p_y),(x,y)),)"
      ],
      "metadata": {
        "id": "6uoESwLR3JmN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in new_coords.keys():\n",
        "  print(key,len(new_coords[key]))"
      ],
      "metadata": {
        "id": "tmMXj9DKebgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_coords"
      ],
      "metadata": {
        "id": "BdfjYbcA-eLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "full_array = []\n",
        "for key in [831]:\n",
        "  temp = new_coords[key]\n",
        "  print(key,len(temp))\n",
        "  temp = temp[1:]\n",
        "  full_array+=temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qSQyaO66hF4w",
        "outputId": "3640b6a7-e83d-411f-8744-fbb7b260dbde"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "831 198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_array"
      ],
      "metadata": {
        "id": "zoUdqxA0d_wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.asarray(full_array)\n",
        "df = pd.DataFrame(a)\n",
        "df = df.drop(columns=[0,3])\n",
        "df = df.rename(columns={ 1: \"x\", 2: \"y\", 4: \"vel\"})\n",
        "df"
      ],
      "metadata": {
        "id": "6ewig5iqgl5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"final_I80_single.csv\",header=['x','y','vel'])\n",
        "#df.to_csv(\"final_101_single.csv\",header=['x','y','vel'])\n",
        "#df.to_csv(\"final_Peach_single.csv\",header=['x','y','vel'])\n",
        "#df.to_csv(\"final_LB_single.csv\",header=['x','y','vel'])\n"
      ],
      "metadata": {
        "id": "xvgyekWchfY8"
      },
      "execution_count": 75,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}